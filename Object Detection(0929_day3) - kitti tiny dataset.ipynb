{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iwGuFH4BZdO0",
    "outputId": "05a839e8-1216-4a07-c451-4a6ae39b9f29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mmcv-full\n",
      "  Downloading mmcv-full-1.3.14.tar.gz (324 kB)\n",
      "\u001b[K     |████████████████████████████████| 324 kB 5.1 MB/s \n",
      "\u001b[?25hCollecting addict\n",
      "  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mmcv-full) (1.19.5)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from mmcv-full) (21.0)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from mmcv-full) (7.1.2)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from mmcv-full) (3.13)\n",
      "Collecting yapf\n",
      "  Downloading yapf-0.31.0-py2.py3-none-any.whl (185 kB)\n",
      "\u001b[K     |████████████████████████████████| 185 kB 46.4 MB/s \n",
      "\u001b[?25hRequirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->mmcv-full) (2.4.7)\n",
      "Building wheels for collected packages: mmcv-full\n",
      "  Building wheel for mmcv-full (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for mmcv-full: filename=mmcv_full-1.3.14-cp37-cp37m-linux_x86_64.whl size=31467569 sha256=16b99f9261f0668705d262f46441989c774623b628c22eb8b69c8efdf7dfb13d\n",
      "  Stored in directory: /root/.cache/pip/wheels/5e/54/62/69c99dc3c9937bca64126f81cbe315ae6c8e6e98c43fa7392d\n",
      "Successfully built mmcv-full\n",
      "Installing collected packages: yapf, addict, mmcv-full\n",
      "Successfully installed addict-2.4.0 mmcv-full-1.3.14 yapf-0.31.0\n"
     ]
    }
   ],
   "source": [
    "!pip install mmcv-full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6YvmL7aDa3Nj",
    "outputId": "66b4013d-740e-47be-b674-fdaaf395fa2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'mmdetection'...\n",
      "remote: Enumerating objects: 21088, done.\u001b[K\n",
      "remote: Counting objects: 100% (1/1), done.\u001b[K\n",
      "remote: Total 21088 (delta 0), reused 0 (delta 0), pack-reused 21087\u001b[K\n",
      "Receiving objects: 100% (21088/21088), 24.81 MiB | 23.11 MiB/s, done.\n",
      "Resolving deltas: 100% (14747/14747), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/open-mmlab/mmdetection.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nsXslfySfrhg",
    "outputId": "c1c796da-4197-4d4f-87d8-d12528f2dc96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/mmdetection\n"
     ]
    }
   ],
   "source": [
    "%cd mmdetection/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ktqnjDeYfvjz"
   },
   "outputs": [],
   "source": [
    "!python setup.py install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "cbrhmRf8h-Ob"
   },
   "outputs": [],
   "source": [
    "mkdir checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wAt0L9bcicbx",
    "outputId": "3c6f5e7a-3073-4111-98d1-42954465a012"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-09-29 06:02:35--  https://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_1x_coco/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth\n",
      "Resolving download.openmmlab.com (download.openmmlab.com)... 47.252.96.35\n",
      "Connecting to download.openmmlab.com (download.openmmlab.com)|47.252.96.35|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 167287506 (160M) [application/octet-stream]\n",
      "Saving to: ‘/content/mmdetection/checkpoints/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth’\n",
      "\n",
      "/content/mmdetectio 100%[===================>] 159.54M  8.44MB/s    in 20s     \n",
      "\n",
      "2021-09-29 06:02:56 (7.86 MB/s) - ‘/content/mmdetection/checkpoints/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth’ saved [167287506/167287506]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -O /content/mmdetection/checkpoints/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth https://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_1x_coco/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "wN1IsszQlCVD"
   },
   "outputs": [],
   "source": [
    "from mmdet.apis import init_detector, inference_detector, show_result_pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "WA2stpR5jVOQ"
   },
   "outputs": [],
   "source": [
    "config_file = \"/content/mmdetection/configs/faster_rcnn/faster_rcnn_r50_fpn_1x_coco.py\"\n",
    "checkpoint_file = \"/content/mmdetection/checkpoints/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZbgW2088CE2x",
    "outputId": "41631154-fc5f-4030-eb63-ffe94f4e973b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-09-29 06:03:56--  https://download.openmmlab.com/mmdetection/data/kitti_tiny.zip\n",
      "Resolving download.openmmlab.com (download.openmmlab.com)... 47.252.96.35\n",
      "Connecting to download.openmmlab.com (download.openmmlab.com)|47.252.96.35|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 6918271 (6.6M) [application/zip]\n",
      "Saving to: ‘kitti_tiny.zip’\n",
      "\n",
      "kitti_tiny.zip      100%[===================>]   6.60M  3.14MB/s    in 2.1s    \n",
      "\n",
      "2021-09-29 06:03:59 (3.14 MB/s) - ‘kitti_tiny.zip’ saved [6918271/6918271]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# download, decompress the data\n",
    "!wget https://download.openmmlab.com/mmdetection/data/kitti_tiny.zip\n",
    "!unzip kitti_tiny.zip > /dev/null\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R-JvQ0wsEoxO"
   },
   "outputs": [],
   "source": [
    "CLASSES = ('Car', 'Van', 'Truck', 'Pedestrian', 'Person_sitting', 'Cyclist', 'Tram', 'Misc', 'DontCare')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "xucyo-uQOYan"
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import os.path as osp\n",
    "\n",
    "import mmcv\n",
    "import numpy as np\n",
    "\n",
    "from mmdet.datasets.builder import DATASETS\n",
    "from mmdet.datasets.custom import CustomDataset\n",
    "\n",
    "@DATASETS.register_module(force=True)\n",
    "class KittiTinyDataset(CustomDataset):\n",
    "\n",
    "    CLASSES = ('Car', 'Pedestrian', 'Cyclist')\n",
    "\n",
    "    ### self.ann_file : /content/kitti_tiny/train.txt\n",
    "    ### self.img_prefix : /content/kitti_tiny/training/image_2\n",
    "    ### ann_file : /content/kitti_tiny/train.txt\n",
    "\n",
    "    def load_annotations(self, ann_file):\n",
    "        cat2label = {k: i for i, k in enumerate(self.CLASSES)}\n",
    "        # load image list from file\n",
    "        image_list = mmcv.list_from_file(self.ann_file)\n",
    "    \n",
    "        data_infos = []\n",
    "        # convert annotations to middle format\n",
    "        for image_id in image_list:\n",
    "            filename = f'{self.img_prefix}/{image_id}.jpeg'\n",
    "            image = mmcv.imread(filename)\n",
    "            height, width = image.shape[:2]\n",
    "    \n",
    "            data_info = dict(filename=f'{image_id}.jpeg', width=width, height=height)\n",
    "    \n",
    "            # load annotations\n",
    "            label_prefix = self.img_prefix.replace('image_2', 'label_2')\n",
    "            lines = mmcv.list_from_file(osp.join(label_prefix, f'{image_id}.txt'))\n",
    "    \n",
    "            content = [line.strip().split(' ') for line in lines]\n",
    "            bbox_names = [x[0] for x in content]\n",
    "            bboxes = [[float(info) for info in x[4:8]] for x in content]\n",
    "    \n",
    "            gt_bboxes = []\n",
    "            gt_labels = []\n",
    "            gt_bboxes_ignore = []\n",
    "            gt_labels_ignore = []\n",
    "    \n",
    "            # filter 'DontCare'\n",
    "            for bbox_name, bbox in zip(bbox_names, bboxes):\n",
    "                if bbox_name in cat2label:\n",
    "                    gt_labels.append(cat2label[bbox_name])\n",
    "                    gt_bboxes.append(bbox)\n",
    "                else:\n",
    "                    gt_labels_ignore.append(-1)\n",
    "                    gt_bboxes_ignore.append(bbox)\n",
    "\n",
    "            data_anno = dict(\n",
    "                bboxes=np.array(gt_bboxes, dtype=np.float32).reshape(-1, 4),\n",
    "                labels=np.array(gt_labels, dtype=np.long),\n",
    "                bboxes_ignore=np.array(gt_bboxes_ignore,\n",
    "                                       dtype=np.float32).reshape(-1, 4),\n",
    "                labels_ignore=np.array(gt_labels_ignore, dtype=np.long))\n",
    "\n",
    "            data_info.update(ann=data_anno)\n",
    "            data_infos.append(data_info)\n",
    "\n",
    "        return data_infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ifvveUxmQOOc",
    "outputId": "ef7a10b9-67a2-4584-aac4-019601a88d75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 163376\n",
      "drwxr-xr-x  2 root root      4096 Sep 29 06:02 .\n",
      "drwxr-xr-x 21 root root      4096 Sep 29 07:04 ..\n",
      "-rw-r--r--  1 root root 167287506 Aug 28  2020 faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth\n"
     ]
    }
   ],
   "source": [
    "!ls -la /content/mmdetection/checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "zu5TQ_2DQTJi"
   },
   "outputs": [],
   "source": [
    "from mmcv import Config\n",
    "cfg = Config.fromfile(config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a0MZf8mNQ9vC",
    "outputId": "89bc8848-cee9-4350-8e03-3bff34c82930"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model = dict(\n",
      "    type='FasterRCNN',\n",
      "    backbone=dict(\n",
      "        type='ResNet',\n",
      "        depth=50,\n",
      "        num_stages=4,\n",
      "        out_indices=(0, 1, 2, 3),\n",
      "        frozen_stages=1,\n",
      "        norm_cfg=dict(type='BN', requires_grad=True),\n",
      "        norm_eval=True,\n",
      "        style='pytorch',\n",
      "        init_cfg=dict(type='Pretrained', checkpoint='torchvision://resnet50')),\n",
      "    neck=dict(\n",
      "        type='FPN',\n",
      "        in_channels=[256, 512, 1024, 2048],\n",
      "        out_channels=256,\n",
      "        num_outs=5),\n",
      "    rpn_head=dict(\n",
      "        type='RPNHead',\n",
      "        in_channels=256,\n",
      "        feat_channels=256,\n",
      "        anchor_generator=dict(\n",
      "            type='AnchorGenerator',\n",
      "            scales=[8],\n",
      "            ratios=[0.5, 1.0, 2.0],\n",
      "            strides=[4, 8, 16, 32, 64]),\n",
      "        bbox_coder=dict(\n",
      "            type='DeltaXYWHBBoxCoder',\n",
      "            target_means=[0.0, 0.0, 0.0, 0.0],\n",
      "            target_stds=[1.0, 1.0, 1.0, 1.0]),\n",
      "        loss_cls=dict(\n",
      "            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\n",
      "        loss_bbox=dict(type='L1Loss', loss_weight=1.0)),\n",
      "    roi_head=dict(\n",
      "        type='StandardRoIHead',\n",
      "        bbox_roi_extractor=dict(\n",
      "            type='SingleRoIExtractor',\n",
      "            roi_layer=dict(type='RoIAlign', output_size=7, sampling_ratio=0),\n",
      "            out_channels=256,\n",
      "            featmap_strides=[4, 8, 16, 32]),\n",
      "        bbox_head=dict(\n",
      "            type='Shared2FCBBoxHead',\n",
      "            in_channels=256,\n",
      "            fc_out_channels=1024,\n",
      "            roi_feat_size=7,\n",
      "            num_classes=80,\n",
      "            bbox_coder=dict(\n",
      "                type='DeltaXYWHBBoxCoder',\n",
      "                target_means=[0.0, 0.0, 0.0, 0.0],\n",
      "                target_stds=[0.1, 0.1, 0.2, 0.2]),\n",
      "            reg_class_agnostic=False,\n",
      "            loss_cls=dict(\n",
      "                type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0),\n",
      "            loss_bbox=dict(type='L1Loss', loss_weight=1.0))),\n",
      "    train_cfg=dict(\n",
      "        rpn=dict(\n",
      "            assigner=dict(\n",
      "                type='MaxIoUAssigner',\n",
      "                pos_iou_thr=0.7,\n",
      "                neg_iou_thr=0.3,\n",
      "                min_pos_iou=0.3,\n",
      "                match_low_quality=True,\n",
      "                ignore_iof_thr=-1),\n",
      "            sampler=dict(\n",
      "                type='RandomSampler',\n",
      "                num=256,\n",
      "                pos_fraction=0.5,\n",
      "                neg_pos_ub=-1,\n",
      "                add_gt_as_proposals=False),\n",
      "            allowed_border=-1,\n",
      "            pos_weight=-1,\n",
      "            debug=False),\n",
      "        rpn_proposal=dict(\n",
      "            nms_pre=2000,\n",
      "            max_per_img=1000,\n",
      "            nms=dict(type='nms', iou_threshold=0.7),\n",
      "            min_bbox_size=0),\n",
      "        rcnn=dict(\n",
      "            assigner=dict(\n",
      "                type='MaxIoUAssigner',\n",
      "                pos_iou_thr=0.5,\n",
      "                neg_iou_thr=0.5,\n",
      "                min_pos_iou=0.5,\n",
      "                match_low_quality=False,\n",
      "                ignore_iof_thr=-1),\n",
      "            sampler=dict(\n",
      "                type='RandomSampler',\n",
      "                num=512,\n",
      "                pos_fraction=0.25,\n",
      "                neg_pos_ub=-1,\n",
      "                add_gt_as_proposals=True),\n",
      "            pos_weight=-1,\n",
      "            debug=False)),\n",
      "    test_cfg=dict(\n",
      "        rpn=dict(\n",
      "            nms_pre=1000,\n",
      "            max_per_img=1000,\n",
      "            nms=dict(type='nms', iou_threshold=0.7),\n",
      "            min_bbox_size=0),\n",
      "        rcnn=dict(\n",
      "            score_thr=0.05,\n",
      "            nms=dict(type='nms', iou_threshold=0.5),\n",
      "            max_per_img=100)))\n",
      "dataset_type = 'CocoDataset'\n",
      "data_root = 'data/coco/'\n",
      "img_norm_cfg = dict(\n",
      "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
      "train_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\n",
      "    dict(type='Resize', img_scale=(1333, 800), keep_ratio=True),\n",
      "    dict(type='RandomFlip', flip_ratio=0.5),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_rgb=True),\n",
      "    dict(type='Pad', size_divisor=32),\n",
      "    dict(type='DefaultFormatBundle'),\n",
      "    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(\n",
      "        type='MultiScaleFlipAug',\n",
      "        img_scale=(1333, 800),\n",
      "        flip=False,\n",
      "        transforms=[\n",
      "            dict(type='Resize', keep_ratio=True),\n",
      "            dict(type='RandomFlip'),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='Pad', size_divisor=32),\n",
      "            dict(type='ImageToTensor', keys=['img']),\n",
      "            dict(type='Collect', keys=['img'])\n",
      "        ])\n",
      "]\n",
      "data = dict(\n",
      "    samples_per_gpu=2,\n",
      "    workers_per_gpu=2,\n",
      "    train=dict(\n",
      "        type='CocoDataset',\n",
      "        ann_file='data/coco/annotations/instances_train2017.json',\n",
      "        img_prefix='data/coco/train2017/',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(type='Resize', img_scale=(1333, 800), keep_ratio=True),\n",
      "            dict(type='RandomFlip', flip_ratio=0.5),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='Pad', size_divisor=32),\n",
      "            dict(type='DefaultFormatBundle'),\n",
      "            dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n",
      "        ]),\n",
      "    val=dict(\n",
      "        type='CocoDataset',\n",
      "        ann_file='data/coco/annotations/instances_val2017.json',\n",
      "        img_prefix='data/coco/val2017/',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(1333, 800),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[123.675, 116.28, 103.53],\n",
      "                        std=[58.395, 57.12, 57.375],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='Pad', size_divisor=32),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='Collect', keys=['img'])\n",
      "                ])\n",
      "        ]),\n",
      "    test=dict(\n",
      "        type='CocoDataset',\n",
      "        ann_file='data/coco/annotations/instances_val2017.json',\n",
      "        img_prefix='data/coco/val2017/',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(1333, 800),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[123.675, 116.28, 103.53],\n",
      "                        std=[58.395, 57.12, 57.375],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='Pad', size_divisor=32),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='Collect', keys=['img'])\n",
      "                ])\n",
      "        ]))\n",
      "evaluation = dict(interval=1, metric='bbox')\n",
      "optimizer = dict(type='SGD', lr=0.02, momentum=0.9, weight_decay=0.0001)\n",
      "optimizer_config = dict(grad_clip=None)\n",
      "lr_config = dict(\n",
      "    policy='step',\n",
      "    warmup='linear',\n",
      "    warmup_iters=500,\n",
      "    warmup_ratio=0.001,\n",
      "    step=[8, 11])\n",
      "runner = dict(type='EpochBasedRunner', max_epochs=12)\n",
      "checkpoint_config = dict(interval=1)\n",
      "log_config = dict(interval=50, hooks=[dict(type='TextLoggerHook')])\n",
      "custom_hooks = [dict(type='NumClassCheckHook')]\n",
      "dist_params = dict(backend='nccl')\n",
      "log_level = 'INFO'\n",
      "load_from = None\n",
      "resume_from = None\n",
      "workflow = [('train', 1)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(cfg.pretty_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8HVrnkXbQ_zt",
    "outputId": "c973db31-2507-4ca0-b6e5-8af333a055d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "model = dict(\n",
      "    type='FasterRCNN',\n",
      "    backbone=dict(\n",
      "        type='ResNet',\n",
      "        depth=50,\n",
      "        num_stages=4,\n",
      "        out_indices=(0, 1, 2, 3),\n",
      "        frozen_stages=1,\n",
      "        norm_cfg=dict(type='BN', requires_grad=True),\n",
      "        norm_eval=True,\n",
      "        style='pytorch',\n",
      "        init_cfg=dict(type='Pretrained', checkpoint='torchvision://resnet50')),\n",
      "    neck=dict(\n",
      "        type='FPN',\n",
      "        in_channels=[256, 512, 1024, 2048],\n",
      "        out_channels=256,\n",
      "        num_outs=5),\n",
      "    rpn_head=dict(\n",
      "        type='RPNHead',\n",
      "        in_channels=256,\n",
      "        feat_channels=256,\n",
      "        anchor_generator=dict(\n",
      "            type='AnchorGenerator',\n",
      "            scales=[8],\n",
      "            ratios=[0.5, 1.0, 2.0],\n",
      "            strides=[4, 8, 16, 32, 64]),\n",
      "        bbox_coder=dict(\n",
      "            type='DeltaXYWHBBoxCoder',\n",
      "            target_means=[0.0, 0.0, 0.0, 0.0],\n",
      "            target_stds=[1.0, 1.0, 1.0, 1.0]),\n",
      "        loss_cls=dict(\n",
      "            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\n",
      "        loss_bbox=dict(type='L1Loss', loss_weight=1.0)),\n",
      "    roi_head=dict(\n",
      "        type='StandardRoIHead',\n",
      "        bbox_roi_extractor=dict(\n",
      "            type='SingleRoIExtractor',\n",
      "            roi_layer=dict(type='RoIAlign', output_size=7, sampling_ratio=0),\n",
      "            out_channels=256,\n",
      "            featmap_strides=[4, 8, 16, 32]),\n",
      "        bbox_head=dict(\n",
      "            type='Shared2FCBBoxHead',\n",
      "            in_channels=256,\n",
      "            fc_out_channels=1024,\n",
      "            roi_feat_size=7,\n",
      "            num_classes=3,\n",
      "            bbox_coder=dict(\n",
      "                type='DeltaXYWHBBoxCoder',\n",
      "                target_means=[0.0, 0.0, 0.0, 0.0],\n",
      "                target_stds=[0.1, 0.1, 0.2, 0.2]),\n",
      "            reg_class_agnostic=False,\n",
      "            loss_cls=dict(\n",
      "                type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0),\n",
      "            loss_bbox=dict(type='L1Loss', loss_weight=1.0))),\n",
      "    train_cfg=dict(\n",
      "        rpn=dict(\n",
      "            assigner=dict(\n",
      "                type='MaxIoUAssigner',\n",
      "                pos_iou_thr=0.7,\n",
      "                neg_iou_thr=0.3,\n",
      "                min_pos_iou=0.3,\n",
      "                match_low_quality=True,\n",
      "                ignore_iof_thr=-1),\n",
      "            sampler=dict(\n",
      "                type='RandomSampler',\n",
      "                num=256,\n",
      "                pos_fraction=0.5,\n",
      "                neg_pos_ub=-1,\n",
      "                add_gt_as_proposals=False),\n",
      "            allowed_border=-1,\n",
      "            pos_weight=-1,\n",
      "            debug=False),\n",
      "        rpn_proposal=dict(\n",
      "            nms_pre=2000,\n",
      "            max_per_img=1000,\n",
      "            nms=dict(type='nms', iou_threshold=0.7),\n",
      "            min_bbox_size=0),\n",
      "        rcnn=dict(\n",
      "            assigner=dict(\n",
      "                type='MaxIoUAssigner',\n",
      "                pos_iou_thr=0.5,\n",
      "                neg_iou_thr=0.5,\n",
      "                min_pos_iou=0.5,\n",
      "                match_low_quality=False,\n",
      "                ignore_iof_thr=-1),\n",
      "            sampler=dict(\n",
      "                type='RandomSampler',\n",
      "                num=512,\n",
      "                pos_fraction=0.25,\n",
      "                neg_pos_ub=-1,\n",
      "                add_gt_as_proposals=True),\n",
      "            pos_weight=-1,\n",
      "            debug=False)),\n",
      "    test_cfg=dict(\n",
      "        rpn=dict(\n",
      "            nms_pre=1000,\n",
      "            max_per_img=1000,\n",
      "            nms=dict(type='nms', iou_threshold=0.7),\n",
      "            min_bbox_size=0),\n",
      "        rcnn=dict(\n",
      "            score_thr=0.05,\n",
      "            nms=dict(type='nms', iou_threshold=0.5),\n",
      "            max_per_img=100)))\n",
      "dataset_type = 'KittiTinyDataset'\n",
      "data_root = '/content/kitti_tiny/'\n",
      "img_norm_cfg = dict(\n",
      "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
      "train_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\n",
      "    dict(type='Resize', img_scale=(1333, 800), keep_ratio=True),\n",
      "    dict(type='RandomFlip', flip_ratio=0.5),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_rgb=True),\n",
      "    dict(type='Pad', size_divisor=32),\n",
      "    dict(type='DefaultFormatBundle'),\n",
      "    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(\n",
      "        type='MultiScaleFlipAug',\n",
      "        img_scale=(1333, 800),\n",
      "        flip=False,\n",
      "        transforms=[\n",
      "            dict(type='Resize', keep_ratio=True),\n",
      "            dict(type='RandomFlip'),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='Pad', size_divisor=32),\n",
      "            dict(type='ImageToTensor', keys=['img']),\n",
      "            dict(type='Collect', keys=['img'])\n",
      "        ])\n",
      "]\n",
      "data = dict(\n",
      "    samples_per_gpu=2,\n",
      "    workers_per_gpu=2,\n",
      "    train=dict(\n",
      "        type='KittiTinyDataset',\n",
      "        ann_file='train.txt',\n",
      "        img_prefix='training/image_2',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(type='Resize', img_scale=(1333, 800), keep_ratio=True),\n",
      "            dict(type='RandomFlip', flip_ratio=0.5),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='Pad', size_divisor=32),\n",
      "            dict(type='DefaultFormatBundle'),\n",
      "            dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n",
      "        ],\n",
      "        data_root='/content/kitti_tiny/'),\n",
      "    val=dict(\n",
      "        type='KittiTinyDataset',\n",
      "        ann_file='val.txt',\n",
      "        img_prefix='training/image_2',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(1333, 800),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[123.675, 116.28, 103.53],\n",
      "                        std=[58.395, 57.12, 57.375],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='Pad', size_divisor=32),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='Collect', keys=['img'])\n",
      "                ])\n",
      "        ],\n",
      "        data_root='/content/kitti_tiny/'),\n",
      "    test=dict(\n",
      "        type='KittiTinyDataset',\n",
      "        ann_file='train.txt',\n",
      "        img_prefix='training/image_2',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(1333, 800),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[123.675, 116.28, 103.53],\n",
      "                        std=[58.395, 57.12, 57.375],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='Pad', size_divisor=32),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='Collect', keys=['img'])\n",
      "                ])\n",
      "        ],\n",
      "        data_root='/content/kitti_tiny/'))\n",
      "evaluation = dict(interval=12, metric='mAP')\n",
      "optimizer = dict(type='SGD', lr=0.0025, momentum=0.9, weight_decay=0.0001)\n",
      "optimizer_config = dict(grad_clip=None)\n",
      "lr_config = dict(\n",
      "    policy='step',\n",
      "    warmup=None,\n",
      "    warmup_iters=500,\n",
      "    warmup_ratio=0.001,\n",
      "    step=[8, 11])\n",
      "runner = dict(type='EpochBasedRunner', max_epochs=12)\n",
      "checkpoint_config = dict(interval=12)\n",
      "log_config = dict(interval=10, hooks=[dict(type='TextLoggerHook')])\n",
      "custom_hooks = [dict(type='NumClassCheckHook')]\n",
      "dist_params = dict(backend='nccl')\n",
      "log_level = 'INFO'\n",
      "load_from = 'checkpoints/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth'\n",
      "resume_from = None\n",
      "workflow = [('train', 1)]\n",
      "work_dir = './tutorial_exps'\n",
      "seed = 0\n",
      "gpu_ids = range(0, 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from mmdet.apis import set_random_seed\n",
    "\n",
    "# Modify dataset type and path\n",
    "cfg.dataset_type = 'KittiTinyDataset'\n",
    "cfg.data_root = '/content/kitti_tiny/'\n",
    "\n",
    "cfg.data.test.type = 'KittiTinyDataset'\n",
    "cfg.data.test.data_root = '/content/kitti_tiny/'\n",
    "cfg.data.test.ann_file = 'train.txt'\n",
    "cfg.data.test.img_prefix = 'training/image_2'\n",
    "\n",
    "cfg.data.train.type = 'KittiTinyDataset'\n",
    "cfg.data.train.data_root = '/content/kitti_tiny/'\n",
    "cfg.data.train.ann_file = 'train.txt'\n",
    "cfg.data.train.img_prefix = 'training/image_2'\n",
    "\n",
    "cfg.data.val.type = 'KittiTinyDataset'\n",
    "cfg.data.val.data_root = '/content/kitti_tiny/'\n",
    "cfg.data.val.ann_file = 'val.txt'\n",
    "cfg.data.val.img_prefix = 'training/image_2'\n",
    "\n",
    "# modify num classes of the model in box head\n",
    "cfg.model.roi_head.bbox_head.num_classes = 3\n",
    "# We can still use the pre-trained Mask RCNN model though we do not need to\n",
    "# use the mask branch\n",
    "cfg.load_from = 'checkpoints/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth'\n",
    "\n",
    "# Set up working dir to save files and logs.\n",
    "cfg.work_dir = './tutorial_exps'\n",
    "\n",
    "# The original learning rate (LR) is set for 8-GPU training.\n",
    "# We divide it by 8 since we only use one GPU.\n",
    "cfg.optimizer.lr = 0.02 / 8\n",
    "cfg.lr_config.warmup = None\n",
    "cfg.log_config.interval = 10\n",
    "\n",
    "cfg.lr_config.policy = 'step'\n",
    "\n",
    "# Change the evaluation metric since we use customized dataset.\n",
    "cfg.evaluation.metric = 'mAP'\n",
    "# We can set the evaluation interval to reduce the evaluation times\n",
    "cfg.evaluation.interval = 12\n",
    "# We can set the checkpoint saving interval to reduce the storage cost\n",
    "cfg.checkpoint_config.interval = 12\n",
    "\n",
    "# Set seed thus the results are more reproducible\n",
    "cfg.seed = 0\n",
    "set_random_seed(0, deterministic=False)\n",
    "cfg.gpu_ids = range(1)\n",
    "\n",
    "\n",
    "# We can initialize the logger for training and have a look\n",
    "# at the final config used for training\n",
    "print(f'Config:\\n{cfg.pretty_text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "1cfLYNmUS90a"
   },
   "outputs": [],
   "source": [
    "from mmdet.datasets import build_dataset\n",
    "from mmdet.models import build_detector\n",
    "from mmdet.apis import train_detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1A6UrhlbTWAn",
    "outputId": "d8f39f9c-31a9-4891-c832-8c0ebcda3516"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/mmdet-2.17.0-py3.7.egg/mmdet/datasets/custom.py:157: UserWarning: CustomDataset does not support filtering empty gt images.\n",
      "  'CustomDataset does not support filtering empty gt images.')\n"
     ]
    }
   ],
   "source": [
    "# train용 데이터 셋 생성\n",
    "\n",
    "datasets = [build_dataset(cfg.data.train)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f1h7R5xgTnsu",
    "outputId": "c7285ae0-0981-4ac5-de6a-6210ca7e8836"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\n",
       " KittiTinyDataset Train dataset with number of images 50, and instance counts: \n",
       " +----------+-------+----------------+-------+-------------+-------+----------+-------+----------+-------+\n",
       " | category | count | category       | count | category    | count | category | count | category | count |\n",
       " +----------+-------+----------------+-------+-------------+-------+----------+-------+----------+-------+\n",
       " |          |       |                |       |             |       |          |       |          |       |\n",
       " | 0 [Car]  | 147   | 1 [Pedestrian] | 23    | 2 [Cyclist] | 7     |          |       |          |       |\n",
       " +----------+-------+----------------+-------+-------------+-------+----------+-------+----------+-------+]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QS-VguH7UFcU",
    "outputId": "c964a455-0334-476b-d8b6-4c71cd1f76ad"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Car', 'Pedestrian', 'Cyclist')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[0].CLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WCt-mlVEUH8L",
    "outputId": "e554a4c9-3fdd-4379-d88e-f247713c17a5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/mmdet-2.17.0-py3.7.egg/mmdet/core/anchor/builder.py:17: UserWarning: ``build_anchor_generator`` would be deprecated soon, please use ``build_prior_generator`` \n",
      "  '``build_anchor_generator`` would be deprecated soon, please use '\n"
     ]
    }
   ],
   "source": [
    "model = build_detector(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
    "model.CLASSES = datasets[0].CLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "egysziuFWIfg",
    "outputId": "f1850216-c3f9-41c2-da37-df7561034a5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 6792\n",
      "drwxr-xr-x  1 root root    4096 Sep 29 07:04 .\n",
      "drwxr-xr-x  1 root root    4096 Sep 29 05:36 ..\n",
      "drwxr-xr-x  4 root root    4096 Sep 16 13:39 .config\n",
      "drwxr-xr-x  2 root root    4096 Sep 29 06:02 .ipynb_checkpoints\n",
      "drwxrwxr-x  3 root root    4096 Jul  5  2020 kitti_tiny\n",
      "-rw-r--r--  1 root root 6918271 Dec 24  2020 kitti_tiny.zip\n",
      "drwxr-xr-x 21 root root    4096 Sep 29 07:04 mmdetection\n",
      "drwxr-xr-x  1 root root    4096 Sep 16 13:40 sample_data\n",
      "drwxr-xr-x  2 root root    4096 Sep 29 06:58 tutorial_exps\n"
     ]
    }
   ],
   "source": [
    "!ls -la"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xwy5Cv2bXWbM",
    "outputId": "a9737c6d-ebe3-409e-8208-76c7b74676f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/mmdetection\n"
     ]
    }
   ],
   "source": [
    "%cd ./mmdetection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HQKDl8kpUvuj",
    "outputId": "12c60ebc-2358-4efe-e7a9-93ad410f7179"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-29 07:21:51,935 - mmdet - INFO - load checkpoint from checkpoints/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth\n",
      "2021-09-29 07:21:51,937 - mmdet - INFO - Use load_from_local loader\n",
      "2021-09-29 07:21:52,096 - mmdet - WARNING - The model and loaded state dict do not match exactly\n",
      "\n",
      "size mismatch for roi_head.bbox_head.fc_cls.weight: copying a param with shape torch.Size([81, 1024]) from checkpoint, the shape in current model is torch.Size([4, 1024]).\n",
      "size mismatch for roi_head.bbox_head.fc_cls.bias: copying a param with shape torch.Size([81]) from checkpoint, the shape in current model is torch.Size([4]).\n",
      "size mismatch for roi_head.bbox_head.fc_reg.weight: copying a param with shape torch.Size([320, 1024]) from checkpoint, the shape in current model is torch.Size([12, 1024]).\n",
      "size mismatch for roi_head.bbox_head.fc_reg.bias: copying a param with shape torch.Size([320]) from checkpoint, the shape in current model is torch.Size([12]).\n",
      "2021-09-29 07:21:52,105 - mmdet - INFO - Start running, host: root@5569cea10591, work_dir: /content/mmdetection/tutorial_exps\n",
      "2021-09-29 07:21:52,108 - mmdet - INFO - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(NORMAL      ) NumClassCheckHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      "(LOW         ) EvalHook                           \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(ABOVE_NORMAL) OptimizerHook                      \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) IterTimerHook                      \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) NumClassCheckHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "2021-09-29 07:21:52,110 - mmdet - INFO - workflow: [('train', 1)], max: 12 epochs\n",
      "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "/usr/local/lib/python3.7/dist-packages/mmdet-2.17.0-py3.7.egg/mmdet/core/anchor/anchor_generator.py:324: UserWarning: ``grid_anchors`` would be deprecated soon. Please use ``grid_priors`` \n",
      "  warnings.warn('``grid_anchors`` would be deprecated soon. '\n",
      "/usr/local/lib/python3.7/dist-packages/mmdet-2.17.0-py3.7.egg/mmdet/core/anchor/anchor_generator.py:361: UserWarning: ``single_level_grid_anchors`` would be deprecated soon. Please use ``single_level_grid_priors`` \n",
      "  '``single_level_grid_anchors`` would be deprecated soon. '\n",
      "2021-09-29 07:22:04,607 - mmdet - INFO - Epoch [1][10/25]\tlr: 2.500e-03, eta: 0:05:54, time: 1.223, data_time: 0.231, memory: 2228, loss_rpn_cls: 0.0316, loss_rpn_bbox: 0.0180, loss_cls: 0.5672, acc: 84.0332, loss_bbox: 0.4016, loss: 1.0183\n",
      "2021-09-29 07:22:14,691 - mmdet - INFO - Epoch [1][20/25]\tlr: 2.500e-03, eta: 0:05:12, time: 1.009, data_time: 0.035, memory: 2228, loss_rpn_cls: 0.0251, loss_rpn_bbox: 0.0127, loss_cls: 0.1958, acc: 93.8086, loss_bbox: 0.3179, loss: 0.5515\n",
      "2021-09-29 07:22:31,830 - mmdet - INFO - Epoch [2][10/25]\tlr: 2.500e-03, eta: 0:04:19, time: 1.201, data_time: 0.226, memory: 2228, loss_rpn_cls: 0.0158, loss_rpn_bbox: 0.0154, loss_cls: 0.1680, acc: 94.5996, loss_bbox: 0.2792, loss: 0.4784\n",
      "2021-09-29 07:22:41,932 - mmdet - INFO - Epoch [2][20/25]\tlr: 2.500e-03, eta: 0:04:11, time: 1.010, data_time: 0.034, memory: 2228, loss_rpn_cls: 0.0118, loss_rpn_bbox: 0.0123, loss_cls: 0.1445, acc: 94.5898, loss_bbox: 0.2191, loss: 0.3877\n",
      "2021-09-29 07:22:58,963 - mmdet - INFO - Epoch [3][10/25]\tlr: 2.500e-03, eta: 0:03:45, time: 1.196, data_time: 0.229, memory: 2228, loss_rpn_cls: 0.0069, loss_rpn_bbox: 0.0113, loss_cls: 0.0948, acc: 96.6016, loss_bbox: 0.1626, loss: 0.2756\n",
      "2021-09-29 07:23:09,108 - mmdet - INFO - Epoch [3][20/25]\tlr: 2.500e-03, eta: 0:03:38, time: 1.014, data_time: 0.035, memory: 2228, loss_rpn_cls: 0.0059, loss_rpn_bbox: 0.0120, loss_cls: 0.1547, acc: 94.0527, loss_bbox: 0.2603, loss: 0.4329\n",
      "2021-09-29 07:23:26,416 - mmdet - INFO - Epoch [4][10/25]\tlr: 2.500e-03, eta: 0:03:18, time: 1.212, data_time: 0.228, memory: 2228, loss_rpn_cls: 0.0105, loss_rpn_bbox: 0.0148, loss_cls: 0.1285, acc: 94.8438, loss_bbox: 0.2240, loss: 0.3778\n",
      "2021-09-29 07:23:36,557 - mmdet - INFO - Epoch [4][20/25]\tlr: 2.500e-03, eta: 0:03:11, time: 1.014, data_time: 0.034, memory: 2228, loss_rpn_cls: 0.0047, loss_rpn_bbox: 0.0125, loss_cls: 0.1225, acc: 95.3418, loss_bbox: 0.1966, loss: 0.3362\n",
      "2021-09-29 07:23:53,716 - mmdet - INFO - Epoch [5][10/25]\tlr: 2.500e-03, eta: 0:02:54, time: 1.210, data_time: 0.227, memory: 2228, loss_rpn_cls: 0.0050, loss_rpn_bbox: 0.0098, loss_cls: 0.1009, acc: 96.0938, loss_bbox: 0.1891, loss: 0.3048\n",
      "2021-09-29 07:24:03,829 - mmdet - INFO - Epoch [5][20/25]\tlr: 2.500e-03, eta: 0:02:46, time: 1.011, data_time: 0.033, memory: 2228, loss_rpn_cls: 0.0068, loss_rpn_bbox: 0.0115, loss_cls: 0.1086, acc: 95.9766, loss_bbox: 0.1743, loss: 0.3012\n",
      "2021-09-29 07:24:21,021 - mmdet - INFO - Epoch [6][10/25]\tlr: 2.500e-03, eta: 0:02:30, time: 1.205, data_time: 0.228, memory: 2228, loss_rpn_cls: 0.0036, loss_rpn_bbox: 0.0094, loss_cls: 0.0829, acc: 96.8457, loss_bbox: 0.1575, loss: 0.2534\n",
      "2021-09-29 07:24:31,216 - mmdet - INFO - Epoch [6][20/25]\tlr: 2.500e-03, eta: 0:02:22, time: 1.020, data_time: 0.035, memory: 2228, loss_rpn_cls: 0.0040, loss_rpn_bbox: 0.0101, loss_cls: 0.0916, acc: 96.4844, loss_bbox: 0.1720, loss: 0.2777\n",
      "2021-09-29 07:24:48,396 - mmdet - INFO - Epoch [7][10/25]\tlr: 2.500e-03, eta: 0:02:07, time: 1.210, data_time: 0.229, memory: 2228, loss_rpn_cls: 0.0034, loss_rpn_bbox: 0.0098, loss_cls: 0.0832, acc: 96.9824, loss_bbox: 0.1548, loss: 0.2513\n",
      "2021-09-29 07:24:58,576 - mmdet - INFO - Epoch [7][20/25]\tlr: 2.500e-03, eta: 0:01:58, time: 1.018, data_time: 0.035, memory: 2228, loss_rpn_cls: 0.0027, loss_rpn_bbox: 0.0121, loss_cls: 0.0942, acc: 96.1914, loss_bbox: 0.1750, loss: 0.2840\n",
      "2021-09-29 07:25:15,862 - mmdet - INFO - Epoch [8][10/25]\tlr: 2.500e-03, eta: 0:01:44, time: 1.209, data_time: 0.229, memory: 2228, loss_rpn_cls: 0.0014, loss_rpn_bbox: 0.0087, loss_cls: 0.0725, acc: 97.0410, loss_bbox: 0.1421, loss: 0.2247\n",
      "2021-09-29 07:25:26,097 - mmdet - INFO - Epoch [8][20/25]\tlr: 2.500e-03, eta: 0:01:35, time: 1.023, data_time: 0.035, memory: 2228, loss_rpn_cls: 0.0022, loss_rpn_bbox: 0.0090, loss_cls: 0.0842, acc: 96.8555, loss_bbox: 0.1704, loss: 0.2658\n",
      "2021-09-29 07:25:43,363 - mmdet - INFO - Epoch [9][10/25]\tlr: 2.500e-04, eta: 0:01:21, time: 1.208, data_time: 0.226, memory: 2228, loss_rpn_cls: 0.0015, loss_rpn_bbox: 0.0089, loss_cls: 0.0659, acc: 97.3535, loss_bbox: 0.1330, loss: 0.2092\n",
      "2021-09-29 07:25:53,666 - mmdet - INFO - Epoch [9][20/25]\tlr: 2.500e-04, eta: 0:01:12, time: 1.031, data_time: 0.034, memory: 2228, loss_rpn_cls: 0.0014, loss_rpn_bbox: 0.0076, loss_cls: 0.0649, acc: 97.5293, loss_bbox: 0.1215, loss: 0.1954\n",
      "2021-09-29 07:26:11,020 - mmdet - INFO - Epoch [10][10/25]\tlr: 2.500e-04, eta: 0:00:58, time: 1.220, data_time: 0.229, memory: 2228, loss_rpn_cls: 0.0036, loss_rpn_bbox: 0.0090, loss_cls: 0.0747, acc: 97.0312, loss_bbox: 0.1390, loss: 0.2263\n",
      "2021-09-29 07:26:21,294 - mmdet - INFO - Epoch [10][20/25]\tlr: 2.500e-04, eta: 0:00:50, time: 1.028, data_time: 0.035, memory: 2228, loss_rpn_cls: 0.0012, loss_rpn_bbox: 0.0065, loss_cls: 0.0680, acc: 97.2852, loss_bbox: 0.1286, loss: 0.2042\n",
      "2021-09-29 07:26:38,623 - mmdet - INFO - Epoch [11][10/25]\tlr: 2.500e-04, eta: 0:00:36, time: 1.216, data_time: 0.231, memory: 2228, loss_rpn_cls: 0.0034, loss_rpn_bbox: 0.0080, loss_cls: 0.0764, acc: 97.0605, loss_bbox: 0.1319, loss: 0.2196\n",
      "2021-09-29 07:26:48,891 - mmdet - INFO - Epoch [11][20/25]\tlr: 2.500e-04, eta: 0:00:27, time: 1.026, data_time: 0.034, memory: 2228, loss_rpn_cls: 0.0014, loss_rpn_bbox: 0.0090, loss_cls: 0.0691, acc: 97.0898, loss_bbox: 0.1357, loss: 0.2151\n",
      "2021-09-29 07:27:06,293 - mmdet - INFO - Epoch [12][10/25]\tlr: 2.500e-05, eta: 0:00:13, time: 1.224, data_time: 0.228, memory: 2228, loss_rpn_cls: 0.0013, loss_rpn_bbox: 0.0063, loss_cls: 0.0620, acc: 97.6074, loss_bbox: 0.1166, loss: 0.1862\n",
      "2021-09-29 07:27:16,560 - mmdet - INFO - Epoch [12][20/25]\tlr: 2.500e-05, eta: 0:00:04, time: 1.026, data_time: 0.034, memory: 2228, loss_rpn_cls: 0.0022, loss_rpn_bbox: 0.0064, loss_cls: 0.0599, acc: 97.6367, loss_bbox: 0.1006, loss: 0.1691\n",
      "2021-09-29 07:27:21,485 - mmdet - INFO - Saving checkpoint at 12 epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 25/25, 3.8 task/s, elapsed: 7s, ETA:     0s\n",
      "---------------iou_thr: 0.5---------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-29 07:27:29,304 - mmdet - INFO - \n",
      "+------------+-----+------+--------+-------+\n",
      "| class      | gts | dets | recall | ap    |\n",
      "+------------+-----+------+--------+-------+\n",
      "| Car        | 62  | 155  | 0.887  | 0.809 |\n",
      "| Pedestrian | 13  | 56   | 0.846  | 0.679 |\n",
      "| Cyclist    | 7   | 65   | 0.571  | 0.100 |\n",
      "+------------+-----+------+--------+-------+\n",
      "| mAP        |     |      |        | 0.529 |\n",
      "+------------+-----+------+--------+-------+\n",
      "2021-09-29 07:27:29,308 - mmdet - INFO - Epoch(val) [12][25]\tAP50: 0.5290, mAP: 0.5292\n"
     ]
    }
   ],
   "source": [
    "mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\n",
    "train_detector(model, datasets, cfg, distributed=False, validate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "mhcn3pnObMMe",
    "outputId": "9207a0be-b6a0-415f-a322-ee348c39c4ed"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'/content/mmdetection'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xaIMkimabMm3",
    "outputId": "b128e318-342f-4b55-fcd1-6d00e2ef8b0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[                                                  ] 0/12751, elapsed: 0s, ETA:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/mmdet-2.17.0-py3.7.egg/mmdet/datasets/utils.py:69: UserWarning: \"ImageToTensor\" pipeline is replaced by \"DefaultFormatBundle\" for batch inference. It is recommended to manually replace it in the test data pipeline in your config file.\n",
      "  'data pipeline in your config file.', UserWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/mmdet-2.17.0-py3.7.egg/mmdet/core/anchor/anchor_generator.py:324: UserWarning: ``grid_anchors`` would be deprecated soon. Please use ``grid_priors`` \n",
      "  warnings.warn('``grid_anchors`` would be deprecated soon. '\n",
      "/usr/local/lib/python3.7/dist-packages/mmdet-2.17.0-py3.7.egg/mmdet/core/anchor/anchor_generator.py:361: UserWarning: ``single_level_grid_anchors`` would be deprecated soon. Please use ``single_level_grid_priors`` \n",
      "  '``single_level_grid_anchors`` would be deprecated soon. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>                      ] 1533/12751, 1.5 task/s, elapsed: 1039s, ETA:  7603s"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mmcv\n",
    "\n",
    "model.cfg = cfg\n",
    "video_reader = mmcv.VideoReader(\"/content/data/songdo_car.mp4\")\n",
    "video_writer = None\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "video_writer = cv2.VideoWriter(\"/content/data/songdo_car_out.mp4\", fourcc, \n",
    "                               video_reader.fps, (video_reader.width, video_reader.height))\n",
    "\n",
    "for frame in mmcv.track_iter_progress(video_reader):\n",
    "    result = inference_detector(model, frame)\n",
    "    frame = model.show_result(frame, result, score_thr=0.4)\n",
    "    video_writer.write(frame)\n",
    "\n",
    "if video_writer:\n",
    "    video_writer.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NhK5weY0q-lc"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Object Detection(0929_day3) - kitti tiny dataset.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
